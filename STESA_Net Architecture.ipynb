{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phe-idz2PC-l",
        "outputId": "e9302629-707e-429b-caa3-22c9f5da6678"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "STESA-Net Architecture"
      ],
      "metadata": {
        "id": "cIybSiQ9QLyG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "class PositionalEncoding(torch.nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:, :x.size(1), :]\n",
        "        return x\n",
        "\n",
        "class SelfAttention(torch.nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(SelfAttention, self).__init__()\n",
        "        self.query = torch.nn.Linear(input_dim, input_dim)\n",
        "        self.key = torch.nn.Linear(input_dim, input_dim)\n",
        "        self.value = torch.nn.Linear(input_dim, input_dim)\n",
        "        self.scale = torch.sqrt(torch.tensor(input_dim, dtype=torch.float32))\n",
        "\n",
        "    def forward(self, x):\n",
        "        Q = self.query(x)\n",
        "        K = self.key(x)\n",
        "        V = self.value(x)\n",
        "        attention_weights = F.softmax(torch.bmm(Q, K.transpose(1, 2)) / self.scale, dim=-1)\n",
        "        return torch.bmm(attention_weights, V)\n",
        "\n",
        "class STESA_Net(torch.nn.Module):\n",
        "    def __init__(self, classes=2, sampleChannel=30, sampleLength=384, num_filters=16, d=2, kernel_size=64, lstm_hidden=64, lstm_layers=5):\n",
        "        super(STESA_Net, self).__init__()\n",
        "        self.bottleneck = torch.nn.Conv2d(1, num_filters, (sampleChannel, 1))\n",
        "        self.temporal = torch.nn.Conv2d(num_filters, d * num_filters, (1, kernel_size), groups=num_filters)\n",
        "        self.activ = torch.nn.ELU(alpha=0.0001)\n",
        "        self.batchnorm = torch.nn.BatchNorm2d(d * num_filters, track_running_stats=False)\n",
        "        self.pool = torch.nn.AvgPool1d(kernel_size=4, stride=4)\n",
        "        self.pos_encoding = PositionalEncoding(d_model=32, max_len=500)\n",
        "        self.attention = SelfAttention(32)\n",
        "        self.lstm = torch.nn.LSTM(\n",
        "            input_size=32,\n",
        "            hidden_size=lstm_hidden,\n",
        "            num_layers=lstm_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=True\n",
        "        )\n",
        "        self.dropout = torch.nn.Dropout(0.3)\n",
        "        self.fc = torch.nn.Linear(lstm_hidden * 2, classes)\n",
        "        self.softmax = torch.nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, inputdata):\n",
        "        block1 = self.bottleneck(inputdata)\n",
        "        block1 = self.temporal(block1)\n",
        "        block1 = self.activ(block1)\n",
        "        block1 = self.batchnorm(block1)\n",
        "        block1 = block1.squeeze(2).permute(0, 2, 1)\n",
        "        block1 = self.pool(block1.permute(0, 2, 1))\n",
        "        block1 = block1.permute(0, 2, 1)\n",
        "        block1 = self.pos_encoding(block1)\n",
        "        block2 = self.attention(block1)\n",
        "        block3, _ = self.lstm(block2)\n",
        "        block3 = self.dropout(block3)\n",
        "        block3 = block3[:, -1, :]\n",
        "        output = self.fc(block3)\n",
        "        output = self.softmax(output)\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "7TS0lVCvPD5y"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Leave-One-Out-validation (LOOV) Main Code"
      ],
      "metadata": {
        "id": "kS6WNg5TQQYn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import scipy.io as sio\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "torch.manual_seed(0)\n",
        "\n",
        "\n",
        "def run():\n",
        "    filename = r'/content/drive/MyDrive/Balanced Nature Dataset.mat'\n",
        "    tmp = sio.loadmat(filename)\n",
        "    xdata = np.array(tmp['EEGsample'])\n",
        "    label = np.array(tmp['substate'])\n",
        "    subIdx = np.array(tmp['subindex'])\n",
        "    label = label.astype(int)\n",
        "    subIdx = subIdx.astype(int)\n",
        "\n",
        "    samplenum = label.shape[0]\n",
        "    channelnum = 30\n",
        "    subjnum = 11\n",
        "    samplelength = 3\n",
        "    sf = 128\n",
        "    lr = 1e-3\n",
        "    batch_size = 50\n",
        "    n_epoch = 11\n",
        "\n",
        "    ydata = np.zeros(samplenum, dtype=np.longlong)\n",
        "    for i in range(samplenum):\n",
        "        ydata[i] = label[i]\n",
        "\n",
        "    results = np.zeros(subjnum)\n",
        "    precision_results = np.zeros(subjnum)\n",
        "    recall_results = np.zeros(subjnum)\n",
        "    f1_results = np.zeros(subjnum)\n",
        "\n",
        "    for i in range(1, subjnum + 1):\n",
        "        trainindx = np.where(subIdx != i)[0]\n",
        "        xtrain = xdata[trainindx]\n",
        "        x_train = xtrain.reshape(xtrain.shape[0], 1, channelnum, samplelength * sf)\n",
        "        y_train = ydata[trainindx]\n",
        "\n",
        "        testindx = np.where(subIdx == i)[0]\n",
        "        xtest = xdata[testindx]\n",
        "        x_test = xtest.reshape(xtest.shape[0], 1, channelnum, samplelength * sf)\n",
        "        y_test = ydata[testindx]\n",
        "\n",
        "        train = torch.utils.data.TensorDataset(torch.from_numpy(x_train), torch.from_numpy(y_train))\n",
        "        train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "        my_net = STESA_Net().double().cuda()\n",
        "        optimizer = optim.Adam(my_net.parameters(), lr=lr)\n",
        "        loss_class = torch.nn.NLLLoss().cuda()\n",
        "\n",
        "        for p in my_net.parameters():\n",
        "            p.requires_grad = True\n",
        "\n",
        "        for epoch in range(n_epoch):\n",
        "            for j, data in enumerate(train_loader, 0):\n",
        "                inputs, labels = data\n",
        "                input_data = inputs.cuda()\n",
        "                class_label = labels.cuda()\n",
        "                my_net.zero_grad()\n",
        "                my_net.train()\n",
        "                class_output = my_net(input_data)\n",
        "                err = loss_class(class_output, class_label)\n",
        "                err.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "        my_net.eval()\n",
        "        with torch.no_grad():\n",
        "            x_test_tensor = torch.DoubleTensor(x_test).cuda()\n",
        "            answer = my_net(x_test_tensor)\n",
        "            probs = answer.cpu().numpy()\n",
        "            preds = probs.argmax(axis=-1)\n",
        "\n",
        "            acc = accuracy_score(y_test, preds)\n",
        "            precision = precision_score(y_test, preds, average='macro', zero_division=0)\n",
        "            recall = recall_score(y_test, preds, average='macro', zero_division=0)\n",
        "            f1 = f1_score(y_test, preds, average='macro', zero_division=0)\n",
        "\n",
        "            print(f'Subject {i}:')\n",
        "            print(f'  Accuracy     = {acc:.4f}')\n",
        "            print(f'  Precision    = {precision:.4f}')\n",
        "            print(f'  Recall       = {recall:.4f} (Sensitivity / Selectivity)')\n",
        "            print(f'  F1 Score     = {f1:.4f}')\n",
        "            print('---------------------------------------------')\n",
        "\n",
        "            results[i - 1] = acc\n",
        "            precision_results[i - 1] = precision\n",
        "            recall_results[i - 1] = recall\n",
        "            f1_results[i - 1] = f1\n",
        "\n",
        "    print('===== Overall Averages =====')\n",
        "    print('Mean Accuracy     :', np.mean(results))\n",
        "    print('Mean Precision    :', np.mean(precision_results))\n",
        "    print('Mean Recall       :', np.mean(recall_results))\n",
        "    print('Mean F1 Score     :', np.mean(f1_results))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    run()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7298qptNQbJs",
        "outputId": "247695e8-2df9-4642-f7f9-079673da5a52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-74f4911fcf63>:31: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  ydata[i] = label[i]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tH75YRDBI39k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}